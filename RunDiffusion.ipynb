{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import models.unet2dcondition as unet\n",
    "import data.dataset_img as ds\n",
    "import data.CI_torch_v2 as CI\n",
    "\n",
    "import data.imgTransforms as imgTransforms\n",
    "\n",
    "import ehtim as eh\n",
    "import copy\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "import imagehash\n",
    "\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "tforms = imgTransforms.imgTransforms()\n",
    "\n",
    "# load model\n",
    "model_name = 'Diffusion_M87_eht2022_230_thnoise_1'\n",
    "\n",
    "# load encoder\n",
    "encoder = 'models/saved_models/DIReCT_v2.pt'\n",
    "encoder = torch.load(encoder, weights_only=False, map_location=device).module.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nxcorr(outputs, labels):\n",
    "    dim = int(outputs.shape[-1])\n",
    "    outputs = outputs.reshape(-1, dim**2)\n",
    "    labels = labels.reshape(-1, dim**2)\n",
    "    \n",
    "    outputs_norm = (outputs.reshape(-1, dim, dim) - torch.nanmean(outputs, axis=1).reshape(-1, 1, 1)) / torch.std(outputs, axis=1).reshape(-1, 1, 1)\n",
    "    labels_norm = (labels.reshape(-1, dim, dim) - torch.nanmean(labels, axis=1).reshape(-1, 1, 1)) / torch.std(labels, axis=1).reshape(-1, 1, 1)\n",
    "\n",
    "    fft_outputs = torch.fft.fftn(outputs_norm, s=[outputs_norm.size(d)*1 for d in [1,2]], dim=[1,2])\n",
    "    fft_labels = torch.fft.fftn(labels_norm, s=[outputs_norm.size(d)*1 for d in [1,2]], dim=[1,2])\n",
    "\n",
    "    xcorr = torch.fft.ifftn(fft_outputs * torch.conj(fft_labels), dim=[1,2])\n",
    "\n",
    "    nxcorr_flat = xcorr.reshape(-1, dim**2)\n",
    "    idx = torch.argmax(torch.abs(nxcorr_flat), dim=1)\n",
    "\n",
    "    return idx, torch.abs(nxcorr_flat[torch.arange(nxcorr_flat.shape[0]), idx])/dim**2\n",
    "\n",
    "def shift_image(im1, im2): # shift single im2 by idx\n",
    "    idx, _ = nxcorr(im1, im2)\n",
    "    im2 = torch.roll(im2, shifts=int(idx))\n",
    "    return im1, im2\n",
    "\n",
    "def shift_all(truth, imgs):\n",
    "    shifted_imgs = []\n",
    "    for img in imgs:\n",
    "        _, shifted_img = shift_image(truth, img)\n",
    "        shifted_imgs.append(shifted_img)\n",
    "    return np.array(shifted_imgs)\n",
    "\n",
    "def weighted_mean_image(imgs, invs, clObj, plot=False):\n",
    "    recon_ci = clObj.FTCI_batch(64, imgs.reshape(-1, imgs.shape[-2], imgs.shape[-1])).reshape(-1, 1, invs.shape[-1])\n",
    "    # recon_ci = clObj.FTCI(imgs.reshape(-1, imgs.shape[-2], imgs.shape[-1])).reshape(-1, 1, invs.shape[-1])\n",
    "    loss = nn.L1Loss(reduction='none')\n",
    "\n",
    "    ciloss = loss(invs, torch.Tensor(recon_ci))\n",
    "    civar = ciloss.reshape(-1, invs.shape[-1]).var(dim=1)\n",
    "    sse = (ciloss.reshape(-1, invs.shape[-1])**2).sum(dim=1)\n",
    "\n",
    "    imgs = imgs.reshape(-1, 1, imgs.shape[-2], imgs.shape[-1])\n",
    "    imgs = imgs[torch.argsort(sse)] # images sorted by loss\n",
    "\n",
    "    weighted_image = torch.zeros_like(imgs[0])\n",
    "    for i in range(imgs.shape[0]):\n",
    "        weighted_image += imgs[i] * 1/civar[i]\n",
    "    weighted_image /= civar.sum()\n",
    "\n",
    "    if plot:\n",
    "        # ci loss histogram\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(2,2))\n",
    "        \n",
    "        ax.hist(sse.detach().cpu().numpy(), bins='fd', edgecolor='black', linewidth=1.2)\n",
    "        ax.set_xlabel('CI SSE')\n",
    "\n",
    "    return imgs, weighted_image.detach().cpu().numpy()[0], sse\n",
    "\n",
    "def plot_images(images, save=False, name='images', cmap='viridis', return_axes=False, show=True):\n",
    "    fig, axes = plt.subplots(2, len(images)//2, figsize=(len(images)//2*0.99, 2))\n",
    "    fig.subplots_adjust(hspace=0., wspace=0.)\n",
    "    axes = axes.flatten()\n",
    "    for ax, img in zip(axes, images):\n",
    "        ax.imshow(img.permute(1, 2, 0), cmap=cmap)\n",
    "        ax.axis('off')\n",
    "    if save:\n",
    "        direc = 'models/history/'+name+'/'\n",
    "        os.makedirs(direc, exist_ok=True)\n",
    "        # check next number\n",
    "        num = 0\n",
    "        while glob.glob(f'{direc}{name}_{num}.png'):\n",
    "            num += 1\n",
    "        plt.savefig(f'{direc}{name}_{num}.png')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    if return_axes:\n",
    "        return axes\n",
    "\n",
    "def findClusters(x, threshold=4, hashsize=6, type=0, verbose=False):\n",
    "    # hash all images\n",
    "    clusters = {}\n",
    "    for img in x:\n",
    "        PIL_img = Image.fromarray(img[0]/np.max(img[0])*255)\n",
    "        hash = imagehash.phash(PIL_img, hash_size=hashsize)\n",
    "        clusters[hash] = clusters.get(hash, []) + [PIL_img]\n",
    "\n",
    "    # group all hashes that are only different by threshold\n",
    "    if type == 0: # Clusters by distance from hashes ordered by L1Loss of closure invariants\n",
    "        moved_hashes = []\n",
    "        for ind, hash in enumerate(clusters.keys()):\n",
    "            if ind != len(clusters.keys()) - 1 and hash not in moved_hashes:\n",
    "                test = np.array([hash - b for b in list(clusters.keys())[ind+1:]])\n",
    "                for i in np.array(list(clusters.keys())[ind+1:])[np.where(test <= threshold)]:\n",
    "                    if i not in moved_hashes:\n",
    "                        moved_hashes.append(i)\n",
    "                        clusters[hash] += clusters[i]\n",
    "        \n",
    "        for i in moved_hashes:\n",
    "            if i in clusters.keys():\n",
    "                del clusters[i]\n",
    "    else:\n",
    "        grouping = {} # Clusters by continuous hash connections\n",
    "        for ind, hash in enumerate(clusters.keys()):\n",
    "            if ind != len(clusters.keys()) - 1:\n",
    "                test = np.array([hash - b for b in list(clusters.keys())[ind+1:]])\n",
    "                for i in np.array(list(clusters.keys())[ind+1:])[np.where(test <= threshold)]:\n",
    "                    if i not in grouping:\n",
    "                        grouping[i] = hash\n",
    "\n",
    "        for i in dict(reversed(list(clusters.items()))):\n",
    "            if i in grouping:\n",
    "                clusters[grouping[i]] += clusters[i]\n",
    "                clusters[i] = []\n",
    "\n",
    "        empty_keys = []\n",
    "        for i in clusters:\n",
    "            if len(clusters[i]) == 0:\n",
    "                empty_keys.append(i)\n",
    "        for i in empty_keys:\n",
    "            del clusters[i]\n",
    "\n",
    "    if verbose:\n",
    "        print('Number of Clusters: ' + str(len(clusters)))\n",
    "\n",
    "    return clusters\n",
    "\n",
    "def ordered_hash(x, target, hashsize=12, cmap='Greys', fide_type='nxcorr', plot=False, num_images = 10):\n",
    "    PIL_img = Image.fromarray(target/np.max(target)*255)\n",
    "    target_hash = imagehash.phash(PIL_img, hash_size=hashsize)\n",
    "    ordered_images = []\n",
    "    for img in x:\n",
    "        PIL_img = Image.fromarray(img[0]/np.max(img[0])*255)\n",
    "        if fide_type == 'hash':\n",
    "            hash = imagehash.phash(PIL_img, hash_size=hashsize)\n",
    "            ordered_images.append([1 - int(hash-target_hash)/hashsize**2, PIL_img])\n",
    "        elif fide_type == 'nxcorr':\n",
    "            xcorr = nxcorr(torch.tensor(img), torch.tensor(target))[1]\n",
    "            ordered_images.append([xcorr, PIL_img])\n",
    "        else:\n",
    "            ordered_images.append([0, None])\n",
    "    ordered_images = sorted(ordered_images, key=lambda x: x[0])[::-1]\n",
    "    if plot:\n",
    "        # flattened images\n",
    "        images = ordered_images[:num_images]\n",
    "        fig, axes = plt.subplots(2, len(images)//2, figsize=(len(images)//2*0.99, 2))\n",
    "        fig.subplots_adjust(hspace=0., wspace=0.)\n",
    "        axes = axes.flatten()\n",
    "        for ax, data in zip(axes, images):\n",
    "            ax.imshow(data[1], cmap=cmap)\n",
    "            ax.axis('off')\n",
    "            ax.text(0.5, 0.9, '%.3f' % data[0], ha='center', va='center', fontsize=8, transform=ax.transAxes, c='white')\n",
    "    return ordered_images\n",
    "\n",
    "def ecdf(a):\n",
    "    x, counts = np.unique(a, return_counts=True)\n",
    "    cusum = np.cumsum(counts)\n",
    "    return x, cusum / cusum[-1]\n",
    "\n",
    "def crps_score(truth, imgs):\n",
    "    imgs = np.array(imgs)\n",
    "    imgs = imgs.reshape(imgs.shape[0], -1)\n",
    "    truth = truth.reshape(-1)\n",
    "\n",
    "    imgs = np.array([i/np.sum(i) for i in imgs])\n",
    "    truth = truth/np.sum(truth)\n",
    "    crps_scores = []\n",
    "    for i in range(imgs.shape[1]):\n",
    "        out_pix = imgs[:, i]\n",
    "        mean_out_pix = np.mean(out_pix)+0.1\n",
    "        truth_pix = truth[i]\n",
    "        x, y = ecdf(out_pix)\n",
    "        step_fc = np.heaviside(x-truth_pix, 0.5)\n",
    "        crps = np.trapz((y-step_fc)**2, x)\n",
    "        crps_scores.append(crps)\n",
    "\n",
    "    crps_scores = np.array(crps_scores).reshape(64, 64)\n",
    "    tot_crps = np.sum(crps_scores)/(truth.shape[0])\n",
    "    return tot_crps, crps_scores    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the clObj\n",
    "\n",
    "tint_sec = 5\n",
    "tadv_sec = 600\n",
    "tstart_hr = 0\n",
    "tstop_hr = 24\n",
    "psize = 1.7044214966184275e-11 # the DIReCT psize\n",
    "bw_hz = [230E9]\n",
    "\n",
    "avg_timescale = 600\n",
    "ehtimAvg=True\n",
    "\n",
    "imgdim = 64\n",
    "\n",
    "uvfits_files = ['M87_eht2022_230_thnoise.uvfits']\n",
    "\n",
    "mask = None\n",
    "\n",
    "ttype='DFT'\n",
    "\n",
    "clObj = CI.Closure_Invariants(tint_sec=tint_sec, tadv_sec=tadv_sec, tstart_hr=tstart_hr, tstop_hr=tstop_hr, bw_hz=bw_hz, psize=psize,\n",
    "                                  uvfits_files = uvfits_files, avg_timescale=avg_timescale, ehtimAvg=ehtimAvg,\n",
    "                                  ci_mask=mask, ttype=ttype, device=device)\n",
    "orig_clObj = copy.deepcopy(clObj)\n",
    "\n",
    "data_dim = clObj.FTCI(np.zeros((1, imgdim, imgdim))).shape[-1]\n",
    "\n",
    "print('Data Dim: ', data_dim)\n",
    "\n",
    "# Network\n",
    "net = unet.UNet2DCondition(ci_dim=data_dim, model_choice=1, encoder_hid_dim=0).to(device).double()\n",
    "noise_scheduler = net.scheduler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image clustering with hashing\n",
    "\n",
    "N_images = 1024\n",
    "\n",
    "load_fits = 'Images/s_mring.fits'\n",
    "useObs = False\n",
    "clObj = copy.deepcopy(orig_clObj)\n",
    "\n",
    "flux = 1.0\n",
    "\n",
    "img = eh.image.load_fits(load_fits)\n",
    "img._imdict['I'] = img.imarr().flatten()/np.sum(img.imarr().flatten()) * flux\n",
    "orig_img = img.copy()\n",
    "\n",
    "img.rf = bw_hz[0]\n",
    "\n",
    "name = load_fits.split('/')[-1].split('.')[0]\n",
    "\n",
    "# img = img.regrid_image(img.fovx(), imgdim)\n",
    "# img.psize = psize\n",
    "img = img.regrid_image(psize*imgdim, imgdim)\n",
    "\n",
    "\n",
    "orig_img = img.copy()\n",
    "\n",
    "\n",
    "im = img.imarr()\n",
    "\n",
    "im = im/np.sum(im) * flux # normalise the intensity \n",
    "\n",
    "# load model from .pt\n",
    "net.load_state_dict(torch.load('models/saved_models/'+model_name+'.pt', map_location=device))\n",
    "\n",
    "\n",
    "x = torch.randn(N_images, 4, 16, 16).to(device)\n",
    "im = torch.tensor(im).reshape(1, 1, 64, 64)#.repeat(N_images, 1, 1, 1)\n",
    "invs = clObj.FTCI(im, useObs=useObs, add_th_noise=True, th_noise_factor=1)\n",
    "invs = invs.to(device).repeat(N_images, 1)\n",
    "invs = invs.reshape(-1, 1, invs.shape[-1])\n",
    "\n",
    "invs = invs.to(torch.float32)\n",
    "net = net.to(torch.float32)\n",
    "x = x.to(torch.float32)\n",
    "\n",
    "x = net.runUnet(x, invs, init_t=0, guidance_scale=None)\n",
    "\n",
    "\n",
    "x = encoder.decoder(x.to(torch.float32))\n",
    "x, x_mean, ciloss = weighted_mean_image(x.cpu(), invs.cpu(), clObj, plot=False)\n",
    "\n",
    "\n",
    "# shift all images\n",
    "x = shift_all(x[0].detach().cpu(), x.detach().cpu()) # according to best\n",
    "\n",
    "\n",
    "print('CRPS: ' + str(crps_score(im.detach().numpy(), x)[0]))\n",
    "\n",
    "\n",
    "clusters = findClusters(x, threshold=4, hashsize=6, type=1, verbose=True)\n",
    "matched_imgs = ordered_hash(x, img.imarr(), hashsize=12, plot=True, fide_type='nxcorr', num_images=64)\n",
    "\n",
    "ngrid = int(np.sqrt(len(clusters)))+1\n",
    "fig, axs = plt.subplots(ngrid, ngrid, figsize=(12, 12))\n",
    "fig.subplots_adjust(hspace=0, wspace=0)\n",
    "axs = axs.flatten()\n",
    "for a in axs:\n",
    "    a.axis('off')\n",
    "\n",
    "\n",
    "for ind, i in enumerate(clusters):\n",
    "    PIL_imgs = clusters[i]\n",
    "    c_images = [torch.tensor(np.asarray(i)) for i in PIL_imgs]\n",
    "    c_rep = torch.tensor(c_images[0])\n",
    "    c_images = shift_all(c_rep, c_images)\n",
    "    c_invs = invs[:len(c_images)]\n",
    "    c_images, c_mean, ciloss = weighted_mean_image(torch.tensor(c_images).unsqueeze(1), c_invs.cpu(), clObj)\n",
    "\n",
    "    axs[ind].imshow(c_mean, cmap='Greys', interpolation='gaussian')\n",
    "    axs[ind].text(0.5, 0.95, 'Cluster ' + str(i) + ': \\n' + str(len(c_images)), ha='center', va='center', fontsize=8, transform=axs[ind].transAxes,)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolutional averaging\n",
    "import models.model_ImageConv as ConvModel\n",
    "\n",
    "add_th_noise = not(useObs)\n",
    "th_noise_factor = 1\n",
    "\n",
    "if not useObs:\n",
    "    clObj.replace_obs_vis(im.squeeze(0), xfov=225, yfov=225)\n",
    "\n",
    "target_ci = invs[0].reshape(1, invs.shape[-1]).cpu()\n",
    "ci_sigmas = clObj.get_CI_MCerror(im, n=1000, useObs=useObs, th_noise_factor=th_noise_factor)\n",
    "\n",
    "print('Median CI SNR: %.2f' % torch.abs(target_ci/ci_sigmas).median())\n",
    "\n",
    "convmodel = ConvModel.ImageConv(x, target_ci, ci_sigmas, clObj, interpF=lambda x: x/x.max(), device=device, interpFactor=1, psizeFactor=1).to(device)\n",
    "\n",
    "convmodel.train(nepochs=100, init_lr=1e-3, decay=0.999, verbose=True, loss_type='L1', weighting=True, loss_reduction='mean', optimiser='Adam')\n",
    "convmodel.train(nepochs=200, init_lr=1e-4, decay=0.999, verbose=False, loss_type='L2', loss_reduction='sum', optimiser='Adam')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Metrics\n",
    "import data.ngEHTMetrics as met\n",
    "\n",
    "res = convmodel().detach().cpu().numpy()\n",
    "out_res = img.copy()\n",
    "out_res._imdict['I'] = res.flatten()/res.sum()\n",
    "\n",
    "img_copy = orig_img.copy()\n",
    "img_copy._imdict['I'] = orig_img.imvec/np.sum(orig_img.imvec)\n",
    "\n",
    "metrics = met.Metrics(img_copy, out_res, clObj)\n",
    "\n",
    "if not useObs:\n",
    "    metrics.update_clObj()\n",
    "\n",
    "chi2_cphase = metrics.chisq_cp()\n",
    "chi2_lcamp = metrics.chisq_lcamp()\n",
    "chi2_ci = metrics.chisq_ci(plot=False)\n",
    "print('Logcamp chi2: %.2f' % chi2_lcamp)\n",
    "print('Cphase chi2: %.2f' % chi2_cphase)\n",
    "print('CI chi2: %.2f' % chi2_ci)\n",
    "\n",
    "\n",
    "fig, ax =plt.subplots(2, 3, figsize=(14.9, 10))\n",
    "fig.subplots_adjust(hspace=0.01, wspace=0.0)\n",
    "titles = ['Truth', 'Best Diffusion', 'GenDIReCT Reconstruction']\n",
    "img.display(axis=ax[0,0], cfun='afmhot', has_title=False, has_cbar=False)\n",
    "ax[0,1].imshow(np.array(matched_imgs[1][1]), cmap='afmhot', interpolation='gaussian')\n",
    "ax[0,2].imshow(res, cmap='afmhot', interpolation='gaussian')\n",
    "for i, a in enumerate(ax.flatten()):\n",
    "    if i < len(titles):\n",
    "        a.axis('off')\n",
    "        a.set_title(titles[i], fontsize=16)\n",
    "\n",
    "ax[1,0].axis('off')\n",
    "\n",
    "_, _, ciloss = weighted_mean_image(torch.tensor(x).cpu(), invs.cpu(), clObj, plot=False)\n",
    "res_ciloss = nn.L1Loss(reduction='none')(target_ci, clObj.FTCI(torch.tensor(res).unsqueeze(0)))**2\n",
    "res_ciloss = res_ciloss.sum(dim=1).detach().cpu().numpy()[0]\n",
    "\n",
    "ax[1,1].hist(ciloss.detach().cpu().numpy(), bins='fd', edgecolor='black', linewidth=1.2, label='Diffusion')\n",
    "ax[1,1].axvline(res_ciloss, color='red', linestyle='dashed', linewidth=2, label='GenDIReCT')\n",
    "ax[1,1].set_xlabel('CI SSE')\n",
    "ax[1,1].legend()\n",
    "\n",
    "nxcorr_dist = [i[0][0].numpy() for i in matched_imgs]\n",
    "res_nxcorr = nxcorr(torch.tensor(res), torch.tensor(im))[1].detach().cpu().numpy()[0]\n",
    "ax[1,2].hist(nxcorr_dist, bins='fd', edgecolor='black', linewidth=1.2)\n",
    "ax[1,2].axvline(res_nxcorr, color='red', linestyle='dashed', linewidth=2)\n",
    "ax[1,2].set_xlabel('NXCORR')\n",
    "ax[1,2].tick_params(left=False, labelleft=False, right=True, labelright=True)\n",
    "\n",
    "\n",
    "effres = metrics.eff_res(plot=False)\n",
    "dynrange = metrics.dynamic_range(effres)\n",
    "\n",
    "ax[0,1].text(0.5, 0.9, '$\\\\rho_{\\\\rm{NX}} =$ %.3f' % matched_imgs[0][0].numpy(), ha='center', va='center', fontsize=8, transform=ax[0,1].transAxes, c='white')\n",
    "ax[0,2].text(0.5, 0.9, '$\\\\rho_{\\\\rm{NX}} =$ %.3f\\n$\\\\theta_{\\\\rm{eff}} =$ %.1f $\\\\mu$as' % (res_nxcorr, effres), ha='center', va='center', fontsize=8, transform=ax[0,2].transAxes, c='white')\n",
    "ax[0,2].text(0.5, 0.1, 'CI SSE = %.4f\\n$\\\\mathcal{D}_{0.1} =$ %.1f' % (res_ciloss, dynrange), ha='center', va='center', fontsize=8, transform=ax[0,2].transAxes, c='white')\n",
    "ax[0,2].text(0.97, 0.5, '$\\\\chi^2_{\\\\rm{cphase}} =$ %.2f\\n$\\\\chi^2_{\\\\rm{lcamp}} =$ %.2f\\n$\\\\chi^2_{\\\\rm{ci}} =$ %.2f' % (chi2_cphase, chi2_lcamp, chi2_ci), ha='right', va='center', fontsize=8, transform=ax[0,2].transAxes, c='white')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
